{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NumberReader_Simple.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORKm6VM4D2MN1vbtWAM7WZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chiharuishida/Pyproject/blob/main/NumberReader_Simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import keras.utils\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "FcV40dIXIyqJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting data from Google API (https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz)\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "Rl25Mnm44AXQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first, let's see what the 28 X 28 pixel number images looks like:\n",
        "plt.imshow(x_train[0], cmap='gray_r')\n",
        "plt.imshow(x_train[2], cmap='gray_r')\n",
        "plt.imshow(x_train[100], cmap='gray_r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "L7Httbh34EnJ",
        "outputId": "4a62d70d-d142-41f0-b72d-05a7b167b3cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f35b5f0e350>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels)=mnist.load_data()\n",
        "\n",
        "print(train_labels[3])\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(784, activation= 'relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(784, activation= 'relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation= 'softmax'))\n",
        "network.compile(optimizer='adam',\n",
        "                loss = 'categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "network=models.Sequential()\n",
        "\n",
        "network.add(layers.Dense(784,activation= 'relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(784,activation= 'relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10,activation= 'softmax'))\n",
        "\n",
        "\n",
        "network.compile(optimizer='adam',\n",
        "                loss = 'categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "train_images = train_images.reshape((60000, 28* 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28* 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "print(train_labels[2])\n",
        "\n",
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "\n",
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "print('test_acc: ', test_acc, 'test_loss', test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VsQ5mtAKF37",
        "outputId": "55b55518-aaec-48e1-995b-87f80f744662"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 12s 24ms/step - loss: 0.2004 - accuracy: 0.9384\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.0743 - accuracy: 0.9762\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.0446 - accuracy: 0.9862\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 12s 27ms/step - loss: 0.0344 - accuracy: 0.9888\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.0269 - accuracy: 0.9908\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0704 - accuracy: 0.9822\n",
            "test_acc:  0.982200026512146 test_loss 0.07043533772230148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's create a submission file with results\n",
        "results = network.predict(test_images)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "results = np.argmax(results,axis = 1)\n",
        "results = pd.Series(results,name=\"Label\")\n",
        "\n",
        "# output\n",
        "submission = pd.concat([pd.Series(range(1,28001), name='ImageId'), results], axis=1)\n",
        "submission.to_csv(\"numberclassification.csv\", index=False)"
      ],
      "metadata": {
        "id": "KOXWai3jKIRj"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}